{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask demo notebook\n",
    "\n",
    "This notebook shows a demonstration of how to use dask and CMAC2.0 on a JupyterHub node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import dask.bag as db\n",
    "import pyart\n",
    "import importlib\n",
    "import netCDF4\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from cmac import cmac, quicklooks, get_sounding_times, get_sounding_file_name, config\n",
    "from IPython.display import Image, display\n",
    "from dask_jobqueue import SLURMCluster, PBSCluster\n",
    "from datetime import datetime\n",
    "from distributed import Client\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client, metrics, wait\n",
    "# wait for jobs to arrive, depending on the queue, this may take some time\n",
    "import dask.array as da\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler, progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subroutine, will do both the processing and plotting for one radar file. A more sophisicated version of this is contained within the cmac_dask script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmac_and_plotting(radar_file_path, cmac_config, sonde_times,\n",
    "                          sounding_files, clutter_file_path, geotiff,\n",
    "                          out_path, img_directory, sweep=3, dd_lobes=False):\n",
    "    \"\"\" For dask we need the radar plotting routines all in one subroutine. \"\"\"\n",
    "    match_datetime = re.search(r'\\d{4}\\d{2}\\d{2}.\\d{6}', radar_file_path)\n",
    "    match_month = re.search(r'\\d{4}\\d{2}', radar_file_path)\n",
    "    file_datetime = match_datetime.group()\n",
    "    file_month = match_month.group()\n",
    "    save_name = cmac_config['save_name']\n",
    "    file_name = (out_path + file_month + '/' + save_name + '.'\n",
    "                 + file_datetime + '.nc')\n",
    "    if os.path.exists(file_name):\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        radar = pyart.io.read(radar_file_path)\n",
    "    except TypeError:\n",
    "        print(radar_file_path + ' has encountered TypeError!')\n",
    "        return\n",
    "\n",
    "    \n",
    "    #radar_start_date = netCDF4.num2date(radar.time['data'][0],\n",
    "     #                                   radar.time['units'], \n",
    "      #                                  only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "\n",
    "    #year_str = \"%04d\" % radar_start_date.year\n",
    "    #month_str = \"%02d\" % radar_start_date.month\n",
    "    #day_str = \"%02d\" % radar_start_date.day\n",
    "    #hour_str = \"%02d\" % radar_start_date.hour\n",
    "    #minute_str = \"%02d\" % radar_start_date.minute\n",
    "    #second_str = \"%02d\" % radar_start_date.second\n",
    "    #save_name = cmac_config['save_name']\n",
    "    #file_name = (out_path + year_str + month_str + '/' + save_name + '.'\n",
    "     #            + year_str + month_str + day_str + '.' + hour_str\n",
    "      #           + minute_str + second_str + '.nc')\n",
    "    rad_time = datetime.strptime(radar.time[\"units\"][0:33], \"seconds since %Y-%m-%d %H:%M:%S\")\n",
    "    # Load clutter files.\n",
    "    #clutter = pyart.io.read(\n",
    "     #   clutter_file_path+'clutter_corcsapr2cfrppiM1.a1'\n",
    "      #  + '.' + year_str + month_str + day_str + '.' + hour_str\n",
    "       # + minute_str + second_str + '.nc')\n",
    "    #clutter_field_dict = clutter.fields['ground_clutter']\n",
    "    #radar.add_field(\n",
    "     #   'ground_clutter', clutter_field_dict, replace_existing=True)\n",
    "    #del clutter\n",
    "    sonde_index = np.argmin(np.abs(sonde_times - rad_time))\n",
    "    sounding_file = sounding_files[sonde_index]\n",
    "    # Retrieve closest sonde in time to the time of the radar file.\n",
    "    sonde = netCDF4.Dataset(sounding_file)\n",
    "    # Running the cmac code to produce a cmac_radar object.\n",
    "    try:\n",
    "        cmac_radar = cmac(radar, sonde, 'cacti_csapr2_ppi', geotiff=geotiff)\n",
    "    except ValueError:\n",
    "        del radar\n",
    "        sonde.close()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        return\n",
    "    # Free up some memory.\n",
    "    del radar\n",
    "    sonde.close()\n",
    "\n",
    "    # Produce the cmac_radar file from the cmac_radar object.\n",
    "    pyart.io.write_cfradial(file_name, cmac_radar)\n",
    "    print('## A CMAC radar object has been created at ' + file_name)\n",
    "\n",
    "    if not os.path.exists(img_directory):\n",
    "        os.makedirs(img_directory)\n",
    "        subprocess.call('chmod -R g+rw ' + img_directory, shell=True)\n",
    "    img_directory = img_directory + year_str + month_str\n",
    "    # Producing all the cmac_radar quicklooks.\n",
    "    quicklooks(cmac_radar, 'cacti_csapr2_ppi',\n",
    "        dd_lobes=False, image_directory=img_directory)\n",
    "\n",
    "    # Delete the cmac_radar object and move on to the next radar file.\n",
    "    del cmac_radar\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to start our dask cluster. Normally, the script to do this on stratus is in qsub_xsapr. The dask-scheduler has to be running on one compute node and the dask-workers on the other computer nodes. However, since we are only on one node, we can just use multiprocessing to do our work for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMAC2.0 has different dictionaries that specify various configurations for the 3 XSAPRs in SGP. Here we will load i5 since the demo data is from XSAPR i5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_config = config.get_metadata('cacti_csapr2_ppi')\n",
    "cmac_config = config.get_cmac_values('cacti_csapr2_ppi')\n",
    "field_config = config.get_field_names('cacti_csapr2_ppi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use a dask bag to map the radar list into distributed memory and then execute the processing code on each file using .map().compute() on the bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundings_directory = '/lustre/or-hydra/cades-arm/proj-shared/corsondewnpnM1.b1/'\n",
    "radar_directory = '/lustre/or-hydra/cades-arm/proj-shared/data_transfer/cor/corcsapr2cfrppiqcM1.b1/*'\n",
    "clutter_directory = '/lustre/or-hydra/cades-arm/proj-shared/csapr2_clutter/'\n",
    "#radar_files = glob(radar_directory + '*/*', recursive=True)\n",
    "radar_files = glob(radar_directory, recursive=True)\n",
    "sounding_files = glob(soundings_directory + '*')\n",
    "#clutter_files = glob(clutter_directory)\n",
    "geotiff = '/lustre/or-hydra/cades-arm/proj-shared/cacti_radardomain.tiff'\n",
    "\n",
    "img_directory = '/lustre/or-hydra/cades-arm/proj-shared/corcsapr2cmacppi.c1.png/'\n",
    "out_path = '/lustre/or-hydra/cades-arm/proj-shared/corcsapr2cmacppi.c1/'\n",
    "log_path = '/lustre/or-hydra/cades-arm/proj-shared/csapr_log/'\n",
    "#sonde_file = '/home/rjackson/i5_test_data/sgpsondewnpnC1.b1.20170926.113600.cdf'\n",
    "#clutter_file_path = '/home/rjackson/clutter201709.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_files.sort()\n",
    "sounding_files.sort()\n",
    "#clutter_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sonde_times(file_list):\n",
    "    time_list = []\n",
    "    for name in file_list:\n",
    "        time_list.append(datetime.strptime(name.split('/')[-1], 'corsondewnpnM1.b1.%Y%m%d.%H%M%S.cdf'))\n",
    "    return np.array(time_list)\n",
    "        \n",
    "#def parse_clutter_times(file_list):\n",
    " #   time_list = []\n",
    "  #  for name in file_list:\n",
    "   #     time_list.append(datetime.strptime(name.split('/')[-1], 'clutter_corcsapr2cfrppiM1.a1.%Y%m%d.%H%M%S.nc'))\n",
    "    #return np.array(time_list)\n",
    "\n",
    "sonde_times = parse_sonde_times(sounding_files)\n",
    "#clutter_times = parse_clutter_times(clutter_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clutter_times.sort()\n",
    "sonde_times.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(radar_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster = PBSCluster(name='dask-worker', memory='270GB', cores=36, processes=6, interface='ib0', queue='high_mem', project='arm',\n",
    "#                    walltime='00:30:00')#, job-extra=['-W group_list=cades-arm'])\n",
    "cluster1 = PBSCluster(processes=9, cores=36, walltime='4:30:00', memory='160GB',\n",
    "                      name='dask-worker', interface='ib0', queue='arm_high_mem', project='arm',\n",
    "                      job_extra=['-W group_list=cades-arm'], extra=['--no-dashboard'])\n",
    "cluster1.scale(4*9)         # Ask for tn workers\n",
    "client1 = Client(cluster1)  # Connect this local process to remote workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1.wait_for_workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_bag = db.from_sequence(radar_files)\n",
    "the_function = lambda x: run_cmac_and_plotting(x, cmac_config, sonde_times,\n",
    "                      sounding_files, clutter_directory, geotiff,\n",
    "                      out_path, img_directory, sweep=3, dd_lobes=False)\n",
    "\n",
    "futures1 = the_bag.map(the_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "progress(futures1.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qselect -u zsherman | xargs qdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cmac_and_plotting(radar_files[9000], cmac_config, sonde_times,\n",
    "                      sounding_files, clutter_directory, geotiff,\n",
    "                      out_path, img_directory, sweep=3, dd_lobes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_file = radar_files[540]\n",
    "radar = pyart.io.read(rad_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_time = datetime.strptime(radar.time[\"units\"][0:33], \"seconds since %Y-%m-%d %H:%M:%S\")\n",
    "sonde_index = np.argmin(np.abs(sonde_times - rad_time))\n",
    "sounding_file = sounding_files[sonde_index]\n",
    "clutter_index = np.argmin(np.abs(clutter_times - rad_time))\n",
    "clutter_file = clutter_files[clutter_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter = pyart.io.read(clutter_file)\n",
    "clutter_field_dict = clutter.fields['ground_clutter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter_field_dict['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in radar.fields.keys():\n",
    "    print(radar.fields[key]['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_files = glob('/lcrc/group/earthscience/icrisologo/csapr_imgs/masked_corrected_reflectivity*.png')\n",
    "im_files.sort()\n",
    "images = []\n",
    "for filename in im_files:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('refl_animation.gif', images, duration=0.5)\n",
    "\n",
    "with open('refl_animation.gif','rb') as f:\n",
    "    display(Image(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar = pyart.io.read(\n",
    "    '/lustre/or-hydra/cades-arm/proj-shared/corcsapr2cfrhsrhi.M1.a1/201901/corcsapr2cfrhsrhiauxM1.a0.20190125.211100.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar.fields.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/lustre/or-hydra/cades-arm/proj-shared/corsondewnpnM1.b1/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import shutil\n",
    "for file in files:\n",
    "    data = netCDF4.Dataset(file)\n",
    "    if data.variables['alt'][:].max() < 20000.0:\n",
    "        shutil.move(file, '/lustre/or-hydra/cades-arm/proj-shared/bad_cor_sonde')\n",
    "\n",
    "        data.close()\n",
    "    else:\n",
    "        data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = netCDF4.Dataset(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar = pyart.io.read('/lustre/or-hydra/cades-arm/proj-shared/corcsapr2cmacppi.c1/201810/cacticsapr2cmacppi.c1.20181031.091504.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar.fields.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar.latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "match = re.search(r'\\d{4}\\d{2}\\d{2}.\\d{6}', radar_files[0])\n",
    "match.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_month = re.search(r'\\d{4}\\d{2}', radar_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_month.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
